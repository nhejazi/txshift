---
title: "IPCW-TMLEs with Stochastic Treatment Regimes"
author: "Nima Hejazi and David Benkeser"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: vignette-refs.bib
vignette: >
  %\VignetteIndexEntry{IPCW-TMLEs with Stochastic Treatment Regimes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo=FALSE}
options(scipen=999)
```

## Introduction

...

---

## Data and Notation

TODO: ADD STUFF ON CENSORING

1. Start with a simple additive shift -- i.e., $d(a,w) = a + \delta$ if
   $a < u(w) - \delta$ or $d(a,w) = a$ if $a \geq u(w) - \delta$.

2. The additive shift will have support everywhere -- i.e., $a < u(w)$ is true
   everywhere.

3. The data structure that we know and love $O = (W,A,Y)$.

### Simulate Data

```{r}
set.seed(429153)
library(tidyverse)

# simulate simple data for tmle-shift sketch
n_obs <- 1000
n_w <- 1
a1_mean <- 2
a0_mean <- 0

## baseline covariate -- simple, binary
W <- as.numeric(replicate(n_w, rbinom(n_obs, 1, 0.5)))

## set and organize treatment based on baseline W
A1 <- rnorm(length(which(W == 1)), mean = a1_mean, sd = 1)
A0 <- rnorm(length(which(W == 0)), mean = a0_mean, sd = 1)
A <- rep(NA, n_obs)
A[which(W == 0)] <- A0
A[which(W == 1)] <- A1

# create outcome
Y <- A + W + rnorm(n_obs)

# censoring based on covariates
C <- rbinom(n_obs, 1, plogis(W))
```

---

## Methodology

### Inverse Probability Weighting with Targeted Maximum Likelihood Estimation

Comments about this estimation procedure...

```{r}
library(condensier)
library(shifttx)
tmle_glm_shift1 <- tmle_shifttx(W = W, A = A, Y = Y, C= C, delta = 0.5,
                                fluc_method = "standard", fit_type = "glm",
                                args = list(
                                  ipcw_fit = list(glm_formula = "Delta ~ ."),
                                  g_fit = list(nbins = 20, bin_method = "dhist",
                                    bin_estimator = speedglmR6$new(),
                                    parfit = FALSE),
                                  Q_fit = list(glm_formula = "Y ~ .")
                                ))
tmle_glm_shift1
```

When computing any such TML estimator, we may, of course, vary the regressions
used in fitting the nuisance parameters; however, an even simpler variation is
to fit the step for the fluctuation submodels with a _weighted_ method, simply
weighting each observation by the so-called "clever" covariate rather than using
such a covariate directly in the regression fit. Please consult [INSERT REF] for
details on potential benefits this approach may have.

```{r}
tmle_glm_shift2 <- tmle_shifttx(W = W, A = A, Y = Y, C = C, delta = 0.5,
                                fluc_method = "weighted", fit_type = "glm",
                                args = list(
                                  ipcw_fit = list(glm_formula = "Delta ~ ."),
                                  g_fit = list(nbins = 20, bin_method = "dhist",
                                    bin_estimator = speedglmR6$new(),
                                    parfit = FALSE),
                                  Q_fit = list(glm_formula = "Y ~ .")
                                ))
tmle_glm_shift2
```

### Interlude: Constructing Super Learners with `sl3`

```{r}
library(sl3)

# SL learners to be used for most fits (e.g., IPCW, outcome regression)
lrn1 <- Lrnr_mean$new()
lrn2 <- Lrnr_glm_fast$new()
lrn3 <- Lrnr_randomForest$new()
sl_lrn <- Lrnr_sl$new(learners = list(lrn1, lrn2, lrn3),
                      metalearner = Lrnr_nnls$new())

# SL learners for conditional densities to be used for the propensity score fit
lrn1_dens <- Lrnr_condensier$new(nbins = 35, bin_estimator = lrn1,
                                 bin_method = "equal.len")
lrn2_dens <- Lrnr_condensier$new(nbins = 25, bin_estimator = lrn2,
                                 bin_method = "equal.len")
sl_lrn_dens <- Lrnr_sl$new(learners = list(lrn1_dens, lrn2_dens),
                           metalearner = Lrnr_solnp_density$new())
```

### Estimating Stochastic Interventions Effects with Super Learners

Using the framework provided by the `sl3` package, the nuisance parameters of
the TML estimator may be fit with ensemble learning, using the cross-validation
framework of the Super Learner algorithm of [INSERT REF].

```{r}
tmle_sl_shift1 <- tmle_shifttx(W = W, A = A, Y = Y, C = C, delta = 0.5,
                               fluc_method = "standard", fit_type = "sl",
                               args = list(
                                 ipcw_fit = list(sl_lrnrs = sl_lrn),
                                 g_fit = list(sl_lrnrs = sl_lrn_dens),
                                 Q_fit = list(sl_lrnrs = sl_lrn)
                               ))
tmle_sl_shift1
```

As before, we may vary the regression for the submodel fluctuation procedure by
weighting each observation by the value of the so-called clever covariate rather
than using such an auxiliary covariate directly in the regression procedure:

```{r}
tmle_sl_shift2 <- tmle_shifttx(W = W, A = A, Y = Y, C = C, delta = 0.5,
                               fluc_method = "weighted", fit_type = "sl",
                               args = list(
                                 ipcw_fit = list(sl_lrnrs = sl_lrn),
                                 g_fit = list(sl_lrnrs = sl_lrn_dens),
                                 Q_fit = list(sl_lrnrs = sl_lrn)
                               ))
tmle_sl_shift2
```

### Statistical Inference for Targeted Maximum Likelihood Estimates

For a discussion of the procedure for obtaining statistical inference for TML
estimators, the interested reader is referred to the introductory vignette of
this package. Here, we focus on addressing the issue of how censoring impacts
the inferential procedure...

```{r}
ci_shift <- confint(tmle_sl_shift1)
ci_shift
```

---

## References
